{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqsdF0XQos_l"
      },
      "source": [
        "# Add all necessary libraries!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JgKtTVe4ooDl"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "@author: Sadman Sakib\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, confusion_matrix\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from PIL import Image\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "\n",
        "from tensorflow.compat.v1 import ConfigProto\n",
        "from tensorflow.compat.v1 import InteractiveSession\n",
        "import warnings\n",
        "import os\n",
        "import shutil\n",
        "from PIL import ImageFile\n",
        "warnings.simplefilter('error', Image.DecompressionBombWarning)\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "Image.MAX_IMAGE_PIXELS = 1000000000\n",
        "config = ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = InteractiveSession(config=config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make it False if do not intend to use Google Colab and want to train in local machine!!\n",
        "google_colab_flag = False\n",
        "\n",
        "# For training in Google Colab\n",
        "if(google_colab_flag):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    !ls\n",
        "    import sys\n",
        "    # This is the path to where in google drive the code is stored!\n",
        "    root_path = '/content/drive/My Drive/Practice/Stratified-k-fold-cross-validation-Image-classification-keras/'\n",
        "    sys.path.append(root_path)\n",
        "\n",
        "# For local training\n",
        "else:\n",
        "    root_path = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wnJCDGu4o5r-"
      },
      "outputs": [],
      "source": [
        "dataset_folder_name = os.path.join(root_path, 'DS')\n",
        "source_files = []\n",
        "class_labels = ['circles', 'squares', 'triangles'] # Change the class names according to your dataset. These names should be the same as the folder names inside train/test/validation\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "img_rows, img_cols = 100, 100  # input image dimensions\n",
        "train_path = os.path.join(dataset_folder_name, 'train')\n",
        "validation_path = os.path.join(dataset_folder_name, 'validation')\n",
        "test_path = os.path.join(dataset_folder_name, 'test')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Vk22FJ2lo980"
      },
      "outputs": [],
      "source": [
        "def transfer_between_folders(source, dest, split_rate):\n",
        "    \"\"\" Based on the split ratio this function moves some portion of the source folder to destination folder!\n",
        "\n",
        "        Args:\n",
        "            source: str\n",
        "                Source folder's path\n",
        "            dest: str\n",
        "                Destination folder's path\n",
        "            split_rate: float\n",
        "                Ratio of files to move from source to dest locaiton\n",
        "\n",
        "    \"\"\"\n",
        "    global source_files\n",
        "    source_files = os.listdir(source)\n",
        "    if(len(source_files) != 0):\n",
        "        transfer_file_numbers = int(len(source_files)*split_rate)\n",
        "        transfer_index = random.sample(\n",
        "            range(0, len(source_files)), transfer_file_numbers)\n",
        "        for each_index in transfer_index:\n",
        "            shutil.move(os.path.join(source, str(source_files[each_index])), os.path.join(\n",
        "                dest, str(source_files[each_index])))\n",
        "\n",
        "    else:\n",
        "        print(\"No file moved. Source empty!\")\n",
        "\n",
        "\n",
        "def transfer_all_class_between_folders(source, dest, split_rate):\n",
        "    \"\"\" Transfer the files from source to dest for all the classes. This function calls the 'transfer_between_folders' to actually perform the transfer.\n",
        "\n",
        "        Args:\n",
        "            source: str\n",
        "                Source folder's path\n",
        "            dest: str\n",
        "                Destination folder's path\n",
        "            split_rate: float\n",
        "                Ratio of files to move from source to dest locaiton\n",
        "\n",
        "    \"\"\"\n",
        "    for label in class_labels:\n",
        "        transfer_between_folders(os.path.join(dataset_folder_name, source, label),\n",
        "                                 os.path.join(\n",
        "                                     dataset_folder_name, dest, label),\n",
        "                                 split_rate)\n",
        "\n",
        "\n",
        "def my_metrics(y_true, y_pred):\n",
        "    \"\"\" Calculate accuracy, precision, and f1 score of the model's prediction with respect to true labels.\n",
        "\n",
        "        Args:\n",
        "            y_true: list/array\n",
        "                All true class labels\n",
        "            y_pred: list/array\n",
        "                All predicted class labels\n",
        "\n",
        "        Returns:\n",
        "            accuracy: float\n",
        "                Accuracy measure of the model\n",
        "            precision: float\n",
        "                Precision measure of the model\n",
        "            f1_Score: float\n",
        "                F1-score measure of the model\n",
        "\n",
        "    \"\"\"\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    f1_Score = f1_score(y_true, y_pred, average='weighted')\n",
        "    print(\"Accuracy  : {}\".format(accuracy))\n",
        "    print(\"Precision : {}\".format(precision))\n",
        "    print(\"f1Score : {}\".format(f1_Score))\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    print(cm)\n",
        "    return accuracy, precision, f1_Score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lutTsY_KpIts"
      },
      "source": [
        "# First, check if test folder is empty or not, if not transfer all existing files to train."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8bnuEdnTo-CL"
      },
      "outputs": [],
      "source": [
        "transfer_all_class_between_folders('test', 'train', 1.0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uf_j9bHZpMp0"
      },
      "source": [
        "# Now, split some part of train data into the test folders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ySOvsWMZpPFl"
      },
      "outputs": [],
      "source": [
        "transfer_all_class_between_folders('train', 'test', 0.20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "X_6tNUr8pw1b"
      },
      "outputs": [],
      "source": [
        "def prepare_name_with_labels(folder_name, dataset_type='train'):\n",
        "    \"\"\" Prepare the file names (X) and the class labels (Y) from folder location of images.\n",
        "\n",
        "        Args:\n",
        "            folder_name: str\n",
        "                Source folder's path\n",
        "\n",
        "    \"\"\"\n",
        "    source_files = os.listdir(os.path.join(dataset_folder_name, dataset_type, folder_name))\n",
        "    y_label = 0\n",
        "    for i in range(len(class_labels)):\n",
        "        if(folder_name == class_labels[i]):\n",
        "            y_label = i\n",
        "    for val in source_files:\n",
        "        X.append(val)\n",
        "        Y.append(y_label)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ABR_vPykp6Fx"
      },
      "outputs": [],
      "source": [
        "# Organize file names and class labels in X and Y variables\n",
        "for i in range(len(class_labels)):\n",
        "    prepare_name_with_labels(class_labels[i])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ct4KgEXpp8vz"
      },
      "outputs": [],
      "source": [
        "X = np.asarray(X)\n",
        "Y = np.asarray(Y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zrlZd93LqAOj"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "epoch = 10\n",
        "num_of_channels = 3\n",
        "number_of_class_labels = len(class_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This is Model 1. The model structure is very trivial, so feel free to optimize the structure of the model!\n",
        "\n",
        "def get_model_1():\n",
        "    activation_function = 'relu'\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, (3, 3), padding='same',\n",
        "                     activation=activation_function, input_shape=(img_rows, img_cols, num_of_channels)))\n",
        "    model.add(Conv2D(64, (3, 3), activation=activation_function))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                     activation=activation_function))\n",
        "    model.add(Conv2D(32, (3, 3), activation=activation_function))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(16, (3, 3), padding='same',\n",
        "                     activation=activation_function))\n",
        "    model.add(Conv2D(16, (3, 3), activation=activation_function))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation=activation_function))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(32, activation=activation_function))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(16, activation=activation_function))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(number_of_class_labels, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "model_1 = get_model_1()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import Xception\n",
        "\n",
        "\n",
        "def get_model_2():\n",
        "    xception = Xception(include_top=False,\n",
        "                        input_shape=(img_rows, img_cols, num_of_channels),\n",
        "                        weights='imagenet')\n",
        "\n",
        "    # trainable rnet\n",
        "    xception.trainable = True\n",
        "    model = tf.keras.Sequential([\n",
        "        xception,\n",
        "        GlobalAveragePooling2D(),\n",
        "        Dense(100, activation='relu'),\n",
        "        Dropout(0.1),\n",
        "        Dense(50, activation='relu'),\n",
        "        Dropout(0.1),\n",
        "        Dense(number_of_class_labels, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "model_2 = get_model_2()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import DenseNet201\n",
        "\n",
        "\n",
        "def get_model_3():\n",
        "    densenet = DenseNet201(\n",
        "        input_shape=(img_rows, img_cols, num_of_channels),\n",
        "        weights='imagenet',\n",
        "        include_top=False\n",
        "    )\n",
        "    # trainable densenet\n",
        "    densenet.trainable = True\n",
        "    model = tf.keras.Sequential([\n",
        "        densenet,\n",
        "        GlobalAveragePooling2D(),\n",
        "        Dense(number_of_class_labels, activation='softmax')\n",
        "    ])\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "model_3 = get_model_3()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "\n",
        "def get_model_4():\n",
        "    vgg16 = VGG16(include_top=False,\n",
        "                  input_shape=(img_rows, img_cols, num_of_channels),\n",
        "                  weights='imagenet')\n",
        "\n",
        "    # trainable rnet\n",
        "    vgg16.trainable = True\n",
        "    model = tf.keras.Sequential([\n",
        "        vgg16,\n",
        "        GlobalAveragePooling2D(),\n",
        "        Dense(100, activation='relu'),\n",
        "        Dropout(0.1),\n",
        "        Dense(50, activation='relu'),\n",
        "        Dropout(0.1),\n",
        "        Dense(number_of_class_labels, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "model_4 = get_model_4()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "\n",
        "\n",
        "def get_model_5():\n",
        "    inception_rnet = InceptionResNetV2(include_top=False,\n",
        "                        input_shape=(img_rows, img_cols, num_of_channels),\n",
        "                        weights='imagenet')\n",
        "\n",
        "    # trainable rnet\n",
        "    inception_rnet.trainable = True\n",
        "    model = tf.keras.Sequential([\n",
        "        inception_rnet,\n",
        "        GlobalAveragePooling2D(),\n",
        "        Dense(100, activation='relu'),\n",
        "        Dropout(0.1),\n",
        "        Dense(50, activation='relu'),\n",
        "        Dropout(0.1),\n",
        "        Dense(number_of_class_labels, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "model_5 = get_model_5()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Stack all models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'model_1': {'accuracy': [], 'precision': [], 'f1_score': []},\n",
              " 'model_2': {'accuracy': [], 'precision': [], 'f1_score': []},\n",
              " 'model_3': {'accuracy': [], 'precision': [], 'f1_score': []},\n",
              " 'model_4': {'accuracy': [], 'precision': [], 'f1_score': []},\n",
              " 'model_5': {'accuracy': [], 'precision': [], 'f1_score': []}}"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_models = {\n",
        "    'model_1': model_1,\n",
        "    'model_2': model_2,\n",
        "    'model_3': model_3,\n",
        "    'model_4': model_4,\n",
        "    'model_5': model_5,\n",
        "}\n",
        "\n",
        "# Create empty dict for storing model performance of K-fold-CV later\n",
        "model_validation_performance_all_folds = dict()\n",
        "\n",
        "for model_index in range(len(all_models)):\n",
        "    model_validation_performance_all_folds['model_'+str(model_index+1)] = {'accuracy': [], 'precision': [], 'f1_score': []}\n",
        "model_validation_performance_all_folds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9_h0Kviqfqp"
      },
      "source": [
        "# **Stratified K-Fold Cross validation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Eey7KqgqUez",
        "outputId": "d19a2140-ce73-45cd-bb85-b96cf6598af6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results for fold 1\n",
            "Found 191 images belonging to 3 classes.\n",
            "Found 64 images belonging to 3 classes.\n",
            "Epoch 1/10\n",
            "3/3 [==============================] - 6s 564ms/step - loss: 1.1070 - accuracy: 0.2984\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 0s 149ms/step - loss: 1.0955 - accuracy: 0.3874\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 0s 135ms/step - loss: 1.1017 - accuracy: 0.3298\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 0s 142ms/step - loss: 1.1025 - accuracy: 0.3089\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 0s 132ms/step - loss: 1.1054 - accuracy: 0.2670\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 0s 133ms/step - loss: 1.1015 - accuracy: 0.3037\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 0s 137ms/step - loss: 1.1010 - accuracy: 0.2827\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 0s 152ms/step - loss: 1.0997 - accuracy: 0.3403\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 1s 155ms/step - loss: 1.0983 - accuracy: 0.3822\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 0s 141ms/step - loss: 1.0979 - accuracy: 0.3455\n",
            "1/1 [==============================] - 0s 142ms/step\n",
            "***Performance on Validation data***\n",
            "Accuracy  : 0.328125\n",
            "Precision : 0.107666015625\n",
            "f1Score : 0.16213235294117648\n",
            "[[ 0 22  0]\n",
            " [ 0 21  0]\n",
            " [ 0 21  0]]\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\sadma\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 7s 731ms/step - loss: 1.0391 - accuracy: 0.5969\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 1s 144ms/step - loss: 0.5797 - accuracy: 0.8901\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 1s 157ms/step - loss: 0.4087 - accuracy: 0.9581\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 1s 153ms/step - loss: 0.4394 - accuracy: 0.9267\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 1s 146ms/step - loss: 0.2106 - accuracy: 0.9529\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 1s 144ms/step - loss: 0.1013 - accuracy: 0.9738\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 1s 148ms/step - loss: 0.0310 - accuracy: 0.9948\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 1s 152ms/step - loss: 0.0175 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 1s 143ms/step - loss: 0.0111 - accuracy: 0.9948\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 1s 139ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "1/1 [==============================] - 1s 585ms/step\n",
            "***Performance on Validation data***\n",
            "Accuracy  : 1.0\n",
            "Precision : 1.0\n",
            "f1Score : 1.0\n",
            "[[22  0  0]\n",
            " [ 0 21  0]\n",
            " [ 0  0 21]]\n",
            "Epoch 1/10\n",
            "3/3 [==============================] - 27s 3s/step - loss: 0.6249 - accuracy: 0.7382\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 1s 215ms/step - loss: 0.1207 - accuracy: 0.9634\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 1s 218ms/step - loss: 0.0578 - accuracy: 0.9895\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 1s 225ms/step - loss: 0.1702 - accuracy: 0.9581\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 1s 218ms/step - loss: 0.0516 - accuracy: 0.9843\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 1s 214ms/step - loss: 0.3444 - accuracy: 0.9372\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 1s 220ms/step - loss: 0.0441 - accuracy: 0.9843\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 1s 215ms/step - loss: 0.0393 - accuracy: 0.9843\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 1s 225ms/step - loss: 0.0231 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 1s 214ms/step - loss: 0.0200 - accuracy: 1.0000\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "***Performance on Validation data***\n",
            "Accuracy  : 0.609375\n",
            "Precision : 0.40842056650246306\n",
            "f1Score : 0.48847587719298247\n",
            "[[22  0  0]\n",
            " [ 9  0 12]\n",
            " [ 4  0 17]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\sadma\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "3/3 [==============================] - 7s 2s/step - loss: 2.1079 - accuracy: 0.2932\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 1s 141ms/step - loss: 1.3533 - accuracy: 0.3613\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 1s 142ms/step - loss: 1.1082 - accuracy: 0.3194\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 1s 150ms/step - loss: 1.1088 - accuracy: 0.3298\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 1s 139ms/step - loss: 1.1167 - accuracy: 0.2880\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 1s 147ms/step - loss: 1.1086 - accuracy: 0.3089\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 1s 140ms/step - loss: 1.1004 - accuracy: 0.3455\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 1s 142ms/step - loss: 1.1075 - accuracy: 0.3403\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 1s 158ms/step - loss: 1.1156 - accuracy: 0.3560\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 1s 141ms/step - loss: 1.1076 - accuracy: 0.3403\n",
            "1/1 [==============================] - 0s 164ms/step\n",
            "***Performance on Validation data***\n",
            "Accuracy  : 0.328125\n",
            "Precision : 0.107666015625\n",
            "f1Score : 0.16213235294117648\n",
            "[[ 0  0 22]\n",
            " [ 0  0 21]\n",
            " [ 0  0 21]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\sadma\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "3/3 [==============================] - 18s 1s/step - loss: 0.8798 - accuracy: 0.6073\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 1s 230ms/step - loss: 0.2458 - accuracy: 0.9162\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 1s 210ms/step - loss: 0.1521 - accuracy: 0.9581\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 1s 214ms/step - loss: 0.1335 - accuracy: 0.9791\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 1s 213ms/step - loss: 0.0306 - accuracy: 0.9843\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 1s 211ms/step - loss: 0.0137 - accuracy: 0.9895\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 1s 205ms/step - loss: 0.0376 - accuracy: 0.9895\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 1s 218ms/step - loss: 0.0320 - accuracy: 0.9948\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 1s 201ms/step - loss: 0.0837 - accuracy: 0.9843\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 1s 208ms/step - loss: 0.0256 - accuracy: 0.9895TA: 0s - loss: 0.0256 - accuracy: 0.98\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000027C8B57D3A8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "***Performance on Validation data***\n",
            "Accuracy  : 0.328125\n",
            "Precision : 0.107666015625\n",
            "f1Score : 0.16213235294117648\n",
            "[[ 0  0 22]\n",
            " [ 0  0 21]\n",
            " [ 0  0 21]]\n",
            "Results for fold 2\n",
            "Found 191 images belonging to 3 classes.\n",
            "Found 64 images belonging to 3 classes.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\sadma\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "3/3 [==============================] - 1s 148ms/step - loss: 1.0978 - accuracy: 0.3874\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 1s 143ms/step - loss: 1.0976 - accuracy: 0.3508\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 0s 152ms/step - loss: 1.0982 - accuracy: 0.3560\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 1s 158ms/step - loss: 1.0968 - accuracy: 0.3403\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 0s 154ms/step - loss: 1.0981 - accuracy: 0.3298\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 0s 149ms/step - loss: 1.0980 - accuracy: 0.3455\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 0s 144ms/step - loss: 1.0983 - accuracy: 0.3037\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 0s 149ms/step - loss: 1.0975 - accuracy: 0.3089\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 1s 157ms/step - loss: 1.0973 - accuracy: 0.3613\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 0s 144ms/step - loss: 1.0977 - accuracy: 0.3822\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "***Performance on Validation data***\n",
            "Accuracy  : 0.328125\n",
            "Precision : 0.107666015625\n",
            "f1Score : 0.16213235294117648\n",
            "[[21  0  0]\n",
            " [22  0  0]\n",
            " [21  0  0]]\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\sadma\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 1s 157ms/step - loss: 0.0418 - accuracy: 0.9791\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 1s 154ms/step - loss: 0.0120 - accuracy: 0.9948\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 1s 149ms/step - loss: 0.0787 - accuracy: 0.9791\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 1s 149ms/step - loss: 0.1577 - accuracy: 0.9895\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 1s 146ms/step - loss: 0.2042 - accuracy: 0.9791\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 1s 158ms/step - loss: 0.1824 - accuracy: 0.9634\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 1s 148ms/step - loss: 0.0654 - accuracy: 0.9895\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.0460 - accuracy: 0.9843\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 1s 153ms/step - loss: 0.0227 - accuracy: 0.9948\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 1s 147ms/step - loss: 0.0269 - accuracy: 0.9843\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "***Performance on Validation data***\n",
            "Accuracy  : 0.6875\n",
            "Precision : 0.8186663879598661\n",
            "f1Score : 0.6075860507246377\n",
            "[[21  0  0]\n",
            " [ 1 21  0]\n",
            " [17  2  2]]\n",
            "Epoch 1/10\n",
            "3/3 [==============================] - 1s 211ms/step - loss: 0.0232 - accuracy: 0.9948\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 1s 214ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 1s 226ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 1s 228ms/step - loss: 5.3153e-04 - accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 1s 225ms/step - loss: 4.0826e-04 - accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 1s 230ms/step - loss: 4.7059e-05 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 1s 222ms/step - loss: 8.9834e-04 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 1s 220ms/step - loss: 3.7129e-04 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 1s 229ms/step - loss: 3.1161e-05 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "***Performance on Validation data***\n",
            "Accuracy  : 0.71875\n",
            "Precision : 0.8040364583333333\n",
            "f1Score : 0.6620656992487772\n",
            "[[21  0  0]\n",
            " [ 5  5 12]\n",
            " [ 1  0 20]]\n",
            "Epoch 1/10\n",
            "3/3 [==============================] - 1s 148ms/step - loss: 1.1052 - accuracy: 0.2565\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 1s 143ms/step - loss: 1.1109 - accuracy: 0.3508\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 1s 155ms/step - loss: 1.1226 - accuracy: 0.3037\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 1s 157ms/step - loss: 1.0877 - accuracy: 0.3717\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 1s 141ms/step - loss: 1.1404 - accuracy: 0.2984\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 1s 160ms/step - loss: 1.1692 - accuracy: 0.3194\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 1s 148ms/step - loss: 1.0990 - accuracy: 0.3613\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 1s 176ms/step - loss: 1.0965 - accuracy: 0.3455\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 1s 137ms/step - loss: 1.1174 - accuracy: 0.2932\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 1s 142ms/step - loss: 1.1047 - accuracy: 0.3455\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "***Performance on Validation data***\n",
            "Accuracy  : 0.421875\n",
            "Precision : 0.3267857142857143\n",
            "f1Score : 0.3359797297297298\n",
            "[[ 0  3 18]\n",
            " [ 0  9 13]\n",
            " [ 0  3 18]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\sadma\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "3/3 [==============================] - 1s 222ms/step - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 1s 213ms/step - loss: 0.0562 - accuracy: 0.9895\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 1s 215ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.1605 - accuracy: 0.9895\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 1s 216ms/step - loss: 0.0121 - accuracy: 0.9948\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 1s 208ms/step - loss: 0.1571 - accuracy: 0.9634\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 1s 209ms/step - loss: 0.0523 - accuracy: 0.9843\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 1s 210ms/step - loss: 0.0954 - accuracy: 0.9948\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 1s 224ms/step - loss: 0.0157 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 1s 218ms/step - loss: 0.0099 - accuracy: 0.9948\n",
            "1/1 [==============================] - 0s 109ms/step\n",
            "***Performance on Validation data***\n",
            "Accuracy  : 0.328125\n",
            "Precision : 0.107666015625\n",
            "f1Score : 0.16213235294117648\n",
            "[[21  0  0]\n",
            " [22  0  0]\n",
            " [21  0  0]]\n",
            "Results for fold 3\n",
            "Found 192 images belonging to 3 classes.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\sadma\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 63 images belonging to 3 classes.\n",
            "Epoch 1/10\n",
            "3/3 [==============================] - 1s 172ms/step - loss: 1.1027 - accuracy: 0.3073\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 1s 156ms/step - loss: 1.1037 - accuracy: 0.2760\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 1s 162ms/step - loss: 1.0992 - accuracy: 0.3594\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 1s 177ms/step - loss: 1.0984 - accuracy: 0.3385\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 1s 148ms/step - loss: 1.0985 - accuracy: 0.3438\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 0s 149ms/step - loss: 1.0983 - accuracy: 0.3542\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 0s 152ms/step - loss: 1.0988 - accuracy: 0.3646\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 0s 147ms/step - loss: 1.0984 - accuracy: 0.3490\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 1s 162ms/step - loss: 1.0988 - accuracy: 0.2917\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 0s 149ms/step - loss: 1.0979 - accuracy: 0.3542\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "***Performance on Validation data***\n",
            "Accuracy  : 0.3333333333333333\n",
            "Precision : 0.1111111111111111\n",
            "f1Score : 0.16666666666666666\n",
            "[[ 0 21  0]\n",
            " [ 0 21  0]\n",
            " [ 0 21  0]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\sadma\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "3/3 [==============================] - 1s 153ms/step - loss: 0.0570 - accuracy: 0.9844\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 1s 161ms/step - loss: 0.0388 - accuracy: 0.9896\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 1s 165ms/step - loss: 0.0462 - accuracy: 0.9792\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 1s 158ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.1303 - accuracy: 0.9896\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 1s 169ms/step - loss: 0.0099 - accuracy: 0.9948\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 1s 162ms/step - loss: 0.0053 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 1s 166ms/step - loss: 0.0428 - accuracy: 0.9896\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 1s 153ms/step - loss: 0.0074 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 1s 180ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "***Performance on Validation data***\n",
            "Accuracy  : 0.9365079365079365\n",
            "Precision : 0.9431818181818182\n",
            "f1Score : 0.9349381204950361\n",
            "[[21  0  0]\n",
            " [ 0 21  0]\n",
            " [ 3  1 17]]\n",
            "Epoch 1/10\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 3.6587e-04 - accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 1s 222ms/step - loss: 0.0148 - accuracy: 0.9948\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 1s 226ms/step - loss: 0.0221 - accuracy: 0.9896\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 1s 228ms/step - loss: 0.0234 - accuracy: 0.9948\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.0319 - accuracy: 0.9844\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.0062 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 1s 224ms/step - loss: 0.0274 - accuracy: 0.9948\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 0.0067 - accuracy: 0.9948\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.0660 - accuracy: 0.9844\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 0.0276 - accuracy: 0.9896\n",
            "1/1 [==============================] - 0s 89ms/step\n",
            "***Performance on Validation data***\n",
            "Accuracy  : 1.0\n",
            "Precision : 1.0\n",
            "f1Score : 1.0\n",
            "[[21  0  0]\n",
            " [ 0 21  0]\n",
            " [ 0  0 21]]\n",
            "Epoch 1/10\n",
            "3/3 [==============================] - 1s 150ms/step - loss: 1.0972 - accuracy: 0.3698\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 1s 148ms/step - loss: 1.0970 - accuracy: 0.3958\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 1s 150ms/step - loss: 1.1034 - accuracy: 0.3229\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 1s 152ms/step - loss: 1.0949 - accuracy: 0.3594\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 1s 147ms/step - loss: 1.0958 - accuracy: 0.3281\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 1s 169ms/step - loss: 1.0992 - accuracy: 0.3229\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 1s 148ms/step - loss: 1.0918 - accuracy: 0.3958\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 1s 150ms/step - loss: 1.0976 - accuracy: 0.3438\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 1s 143ms/step - loss: 1.0859 - accuracy: 0.4167\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 1s 156ms/step - loss: 1.0661 - accuracy: 0.4635\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "***Performance on Validation data***\n",
            "Accuracy  : 0.6349206349206349\n",
            "Precision : 0.8119135046919624\n",
            "f1Score : 0.5490530303030303\n",
            "[[ 1  1 19]\n",
            " [ 0 18  3]\n",
            " [ 0  0 21]]\n",
            "Epoch 1/10\n",
            "3/3 [==============================] - 1s 219ms/step - loss: 0.0150 - accuracy: 0.9948\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 1s 276ms/step - loss: 0.0153 - accuracy: 0.9948\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 1s 214ms/step - loss: 0.0668 - accuracy: 0.9896\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 1s 216ms/step - loss: 0.0654 - accuracy: 0.9792\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 1s 216ms/step - loss: 0.0254 - accuracy: 0.9896\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 1s 222ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 1s 220ms/step - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 1s 229ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 1s 218ms/step - loss: 0.0064 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 0.0205 - accuracy: 0.9948\n",
            "1/1 [==============================] - 0s 103ms/step\n",
            "***Performance on Validation data***\n",
            "Accuracy  : 0.8412698412698413\n",
            "Precision : 0.8814814814814814\n",
            "f1Score : 0.842885872297637\n",
            "[[17  0  4]\n",
            " [ 1 15  5]\n",
            " [ 0  0 21]]\n"
          ]
        }
      ],
      "source": [
        "# ===============Stratified K-Fold======================\n",
        "skf = StratifiedKFold(n_splits=3, shuffle=True)\n",
        "skf.get_n_splits(X, Y)\n",
        "fold_num = 0\n",
        "for train_index, val_index in skf.split(X, Y):\n",
        "    # First cut all images from validation to train (if any exists)\n",
        "    transfer_all_class_between_folders('validation', 'train', 1.0)\n",
        "    fold_num += 1\n",
        "    print(\"Results for fold\", fold_num)\n",
        "    X_train, X_val = X[train_index], X[val_index]\n",
        "    Y_train, Y_val = Y[train_index], Y[val_index]\n",
        "\n",
        "    # Move validation images of this fold from train folder to the validation folder\n",
        "    for each_index in range(len(X_val)):\n",
        "        class_label = ''\n",
        "        for i in range(len(class_labels)):\n",
        "            if(Y_val[each_index] == i):\n",
        "                class_label = class_labels[i]\n",
        "        # Then, copy the validation images to the validation folder\n",
        "        shutil.move(os.path.join(dataset_folder_name, 'train', class_label, X_val[each_index]),\n",
        "                    os.path.join(dataset_folder_name, 'validation', class_label, X_val[each_index]))\n",
        "\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        zoom_range=0.20,\n",
        "        fill_mode=\"nearest\")\n",
        "    validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    # Start ImageClassification Model\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        target_size=(img_rows, img_cols),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        subset='training')\n",
        "\n",
        "    validation_generator = validation_datagen.flow_from_directory(\n",
        "        validation_path,\n",
        "        target_size=(img_rows, img_cols),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,  # only data, no labels\n",
        "        shuffle=False)\n",
        "\n",
        "    # Get true class labels of validation data\n",
        "    true_classes = validation_generator.classes\n",
        "\n",
        "    # Train all the models and save performance of each model on validation dataset\n",
        "    for model_index in range(len(all_models)):\n",
        "        # Fit model\n",
        "        history = all_models['model_'+str(model_index+1)].fit(train_generator,\n",
        "                            epochs=epoch)\n",
        "\n",
        "        predictions = all_models['model_'+str(model_index+1)].predict(validation_generator, verbose=1)\n",
        "        y_predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "        # Evaluate validation performance\n",
        "        print(\"***Performance on Validation data***\")\n",
        "        val_acc, val_prec, val_fScore = my_metrics(true_classes, y_predictions)\n",
        "\n",
        "        model_validation_performance_all_folds['model_'+str(model_index+1)]['accuracy'].append(val_acc)\n",
        "        model_validation_performance_all_folds['model_'+str(model_index+1)]['precision'].append(val_prec)\n",
        "        model_validation_performance_all_folds['model_'+str(model_index+1)]['f1_score'].append(val_fScore)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Check performance of all models for all folds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'model_1': {'accuracy': [0.328125, 0.328125, 0.3333333333333333],\n",
              "  'precision': [0.107666015625, 0.107666015625, 0.1111111111111111],\n",
              "  'f1_score': [0.16213235294117648, 0.16213235294117648, 0.16666666666666666]},\n",
              " 'model_2': {'accuracy': [1.0, 0.6875, 0.9365079365079365],\n",
              "  'precision': [1.0, 0.8186663879598661, 0.9431818181818182],\n",
              "  'f1_score': [1.0, 0.6075860507246377, 0.9349381204950361]},\n",
              " 'model_3': {'accuracy': [0.609375, 0.71875, 1.0],\n",
              "  'precision': [0.40842056650246306, 0.8040364583333333, 1.0],\n",
              "  'f1_score': [0.48847587719298247, 0.6620656992487772, 1.0]},\n",
              " 'model_4': {'accuracy': [0.328125, 0.421875, 0.6349206349206349],\n",
              "  'precision': [0.107666015625, 0.3267857142857143, 0.8119135046919624],\n",
              "  'f1_score': [0.16213235294117648, 0.3359797297297298, 0.5490530303030303]},\n",
              " 'model_5': {'accuracy': [0.328125, 0.328125, 0.8412698412698413],\n",
              "  'precision': [0.107666015625, 0.107666015625, 0.8814814814814814],\n",
              "  'f1_score': [0.16213235294117648, 0.16213235294117648, 0.842885872297637]}}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_validation_performance_all_folds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'model_1': {'accuracy': 0.3298611111111111,\n",
              "  'precision': 0.10881438078703703,\n",
              "  'f1_score': 0.1636437908496732},\n",
              " 'model_2': {'accuracy': 0.8746693121693122,\n",
              "  'precision': 0.9206160687138948,\n",
              "  'f1_score': 0.8475080570732246},\n",
              " 'model_3': {'accuracy': 0.7760416666666666,\n",
              "  'precision': 0.7374856749452654,\n",
              "  'f1_score': 0.7168471921472532},\n",
              " 'model_4': {'accuracy': 0.46164021164021163,\n",
              "  'precision': 0.4154550782008923,\n",
              "  'f1_score': 0.34905503765797885},\n",
              " 'model_5': {'accuracy': 0.49917328042328046,\n",
              "  'precision': 0.3656045042438271,\n",
              "  'f1_score': 0.38905019272666336}}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Aggregate all models' peformance measures for k folds\n",
        "for model_index in range(len(all_models)):\n",
        "    model_validation_performance_all_folds['model_'+str(model_index+1)]['accuracy'] = np.mean(model_validation_performance_all_folds['model_'+str(model_index+1)]['accuracy'])\n",
        "    model_validation_performance_all_folds['model_'+str(model_index+1)]['precision'] = np.mean(model_validation_performance_all_folds['model_'+str(model_index+1)]['precision'])\n",
        "    model_validation_performance_all_folds['model_'+str(model_index+1)]['f1_score'] = np.mean(model_validation_performance_all_folds['model_'+str(model_index+1)]['f1_score'])\n",
        "\n",
        "model_validation_performance_all_folds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_1</th>\n",
              "      <th>model_2</th>\n",
              "      <th>model_3</th>\n",
              "      <th>model_4</th>\n",
              "      <th>model_5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>accuracy</th>\n",
              "      <td>0.329861</td>\n",
              "      <td>0.874669</td>\n",
              "      <td>0.776042</td>\n",
              "      <td>0.461640</td>\n",
              "      <td>0.499173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.108814</td>\n",
              "      <td>0.920616</td>\n",
              "      <td>0.737486</td>\n",
              "      <td>0.415455</td>\n",
              "      <td>0.365605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1_score</th>\n",
              "      <td>0.163644</td>\n",
              "      <td>0.847508</td>\n",
              "      <td>0.716847</td>\n",
              "      <td>0.349055</td>\n",
              "      <td>0.389050</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            model_1   model_2   model_3   model_4   model_5\n",
              "accuracy   0.329861  0.874669  0.776042  0.461640  0.499173\n",
              "precision  0.108814  0.920616  0.737486  0.415455  0.365605\n",
              "f1_score   0.163644  0.847508  0.716847  0.349055  0.389050"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert the dict to a datafrmae\n",
        "import pandas as pd\n",
        "all_model_performance_df = pd.DataFrame(model_validation_performance_all_folds)\n",
        "all_model_performance_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Performance measure')"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 864x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot the performance values in bar chart\n",
        "from matplotlib import pyplot as plt\n",
        "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
        "plt.rcParams[\"font.size\"] = \"16\"\n",
        "plt.rcParams[\"figure.figsize\"] = (12,7)\n",
        "\n",
        "all_model_performance_df.plot.bar(rot=0)\n",
        "plt.title('All model average performance for all folds', )\n",
        "plt.xlabel(\"Metric\")\n",
        "plt.ylabel(\"Performance measure\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pick best models as the final models "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model_2    0.847508\n",
            "model_3    0.716847\n",
            "model_5    0.389050\n",
            "Name: f1_score, dtype: float64\n",
            "*** The best 3 models ***\n",
            "['model_2', 'model_3', 'model_5']\n"
          ]
        }
      ],
      "source": [
        "# The top N models to use in the final ensemble. This value should be less than the number of total models used (e.g., 5)\n",
        "best_n = 3 # Here, we are picking the top 3 models out of 5 models. This value can be changed depnding on how many models you want to keep!\n",
        "target_performance_metric = 'f1_score' # This can be changed to accuracy or precision also, depending on the goal of the task!\n",
        "best_n_models = all_model_performance_df.loc[target_performance_metric].sort_values(ascending=False)[:best_n]\n",
        "print(best_n_models) # Printing the best models' performance values (i.e., f1_score)\n",
        "print(\"*** The best\", best_n, \"models ***\")\n",
        "best_n_models = list(best_n_models.index)\n",
        "print(best_n_models) # Printing the names of the top models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvIlpPcxqaf3"
      },
      "source": [
        "# Test phase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doo1xZFqqW1H",
        "outputId": "c91d9f79-7ec3-4a9e-86a2-c0c18601ecf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============= TEST RESULTS ============\n",
            "Found 45 images belonging to 3 classes.\n",
            "model_2\n",
            "1/1 [==============================] - 0s 471ms/step\n",
            "Accuracy  : 0.9777777777777777\n",
            "Precision : 0.9791666666666666\n",
            "f1Score : 0.9777530589543938\n",
            "[[15  0  0]\n",
            " [ 0 15  0]\n",
            " [ 0  1 14]]\n",
            "model_3\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Accuracy  : 0.9777777777777777\n",
            "Precision : 0.9791666666666666\n",
            "f1Score : 0.9777530589543938\n",
            "[[15  0  0]\n",
            " [ 0 15  0]\n",
            " [ 1  0 14]]\n",
            "model_5\n",
            "1/1 [==============================] - 1s 809ms/step\n",
            "Accuracy  : 0.9111111111111111\n",
            "Precision : 0.9163398692810457\n",
            "f1Score : 0.9109126984126985\n",
            "[[13  2  0]\n",
            " [ 0 13  2]\n",
            " [ 0  0 15]]\n",
            "*** Ensemble soft voting performance ***\n",
            "Accuracy  : 1.0\n",
            "Precision : 1.0\n",
            "f1Score : 1.0\n",
            "[[15  0  0]\n",
            " [ 0 15  0]\n",
            " [ 0  0 15]]\n"
          ]
        }
      ],
      "source": [
        "print(\"============= TEST RESULTS ============\")\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=(img_rows, img_cols),\n",
        "    batch_size=batch_size,\n",
        "    class_mode=None,\n",
        "    shuffle=False \n",
        ")\n",
        "true_classes = test_generator.classes\n",
        "best_n_model_y_preds = []\n",
        "\n",
        "# Get the predictions of each model and check individual model's performance\n",
        "for model in best_n_models:\n",
        "    print(model)\n",
        "    predictions = all_models[model].predict(test_generator, verbose=1)\n",
        "    best_n_model_y_preds.append(predictions)\n",
        "    y_predictions = np.argmax(predictions, axis=1)\n",
        "    my_metrics(true_classes, y_predictions)\n",
        "    \n",
        "# Use the soft voting ensemble technique (by taking the average of the model's predicted probability)\n",
        "y_predicted_probabilites_ensemble = np.mean(best_n_model_y_preds, axis=0) \n",
        "y_predictions_ensemble = np.argmax(y_predicted_probabilites_ensemble, axis=1)\n",
        "print('*** Ensemble soft voting performance ***')\n",
        "test_acc, test_prec, test_fScore = my_metrics(true_classes, y_predictions_ensemble)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "stratified-K-fold-CV.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.7.11 ('deeplearning')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "vscode": {
      "interpreter": {
        "hash": "94d6c109392c71b662221930059c91b3f76abbd2cf09d0c9ff25a72281299be0"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
